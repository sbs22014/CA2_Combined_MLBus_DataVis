{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8641dc9",
   "metadata": {},
   "source": [
    "# Create Dashboard on DASH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce7781b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "from jupyter_dash import JupyterDash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "import pandas as pd\n",
    "import dash\n",
    "from dash import dcc, html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098c0b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all dfs for our dashbaord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b43435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('dash_df1.csv')\n",
    "df2 = pd.read_csv('dash_df2.csv')\n",
    "df3 = pd.read_csv('dash_df3.csv')\n",
    "df4 = pd.read_csv('dash_df4.csv')\n",
    "df5 = pd.read_csv('dash_df5.csv')\n",
    "df6 = pd.read_csv('dash_df6.csv')\n",
    "df7 = pd.read_csv('dash_df2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b568f1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aad.sray\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\aad.sray\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Essential to 6th Visualisation\n",
    "\n",
    "df6 = pd.read_csv('dfplotf.csv')\n",
    "import string\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import statistics\n",
    "\n",
    "# Download the required NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Create SentimentIntensityAnalyzer instance\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "# Function to calculate sentiment scores\n",
    "def calculate_sentiment_scores(comment):\n",
    "    sia = SentimentIntensityAnalyzer()\n",
    "    sentiment_score = sia.polarity_scores(comment)['compound']\n",
    "    return sentiment_score\n",
    "\n",
    "# Function to calculate word frequencies\n",
    "def process_comments_and_get_metrics(df6):\n",
    "    comments = ' '.join(df6['Comment']).lower()\n",
    "    comments = comments.translate(str.maketrans('', '', string.punctuation))  \n",
    "    word_list = comments.split()\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_list = [word for word in word_list if word not in stop_words]\n",
    "\n",
    "    # Calculate sentiment scores for each comment\n",
    "    df6['Sentiment'] = df6['Comment'].apply(calculate_sentiment_scores)\n",
    "    \n",
    "    # Calculate word frequencies\n",
    "    word_freq = Counter(word_list)\n",
    "    \n",
    "    # Ensure the lengths match\n",
    "    common_length = min(len(word_freq), len(df6))\n",
    "    \n",
    "    return pd.DataFrame({\n",
    "        'Word': list(word_freq.keys())[:common_length],\n",
    "        'Frequency': list(word_freq.values())[:common_length],\n",
    "        'Sentiment': df6['Sentiment'].iloc[:common_length].tolist()  \n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9d8a79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\aad.sray\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\aad.sray\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\aad.sray\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8086/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x297ec70cdd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.express as px\n",
    "from wordcloud import WordCloud\n",
    "import io\n",
    "import base64\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download(\"vader_lexicon\")\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "import plotly.express as px\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "import string\n",
    "\n",
    "\n",
    "# Import Libraries\n",
    "\n",
    "df1 = pd.read_csv('datavisnew.csv')\n",
    "df1['Time'] = pd.to_datetime(df1['Time'])\n",
    "df2 = pd.read_csv('datavismins.csv')\n",
    "df2['Time'] = pd.to_datetime(df2['Time'])\n",
    "df3 = pd.read_csv('visdf.csv')\n",
    "df3['Time'] = pd.to_datetime(df3['Time'])\n",
    "df3['Hour'] = df3['Time'].dt.hour\n",
    "df4 = pd.read_csv('dfplotd.csv')\n",
    "df5 = pd.read_csv('plotedf.csv')\n",
    "df_pie = df5.groupby('Sentiment Category').size().reset_index(name='Count')\n",
    "df6 = pd.read_csv('dfplotf.csv')\n",
    "df7 = pd.read_csv('dash_df2.csv')\n",
    "df7['Time'] = pd.to_datetime(df7['Time'])\n",
    "df7['Hour'] = df7['Time'].dt.hour\n",
    "\n",
    "# Heat map code pre-reqs \n",
    "\n",
    "heatmap_data = df7.pivot_table(values='Score', index='Hour', aggfunc='mean').reset_index()\n",
    "max_columns = 6\n",
    "num_rows = (len(heatmap_data) + max_columns - 1) // max_columns\n",
    "heatmap_matrix = np.zeros((num_rows, max_columns))\n",
    "indices = heatmap_data['Hour'].values\n",
    "heatmap_matrix[np.arange(len(indices)) // max_columns, np.arange(len(indices)) % max_columns] = heatmap_data['Score']\n",
    "\n",
    "# Generate word cloud topic\n",
    "def generate_wordcloud(topic):\n",
    "    comments = ' '.join(df4[df4['Topic'] == topic]['Comment'])\n",
    "    if not comments:\n",
    "        return None\n",
    "\n",
    "    # Set style parameters \n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='black', colormap='plasma', collocations=False).generate(comments)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    img_buf = io.BytesIO()\n",
    "    plt.savefig(img_buf, format='png')\n",
    "    img_buf.seek(0)\n",
    "    img_base64 = base64.b64encode(img_buf.read()).decode('utf-8')\n",
    "    plt.close()\n",
    "    return f'data:image/png;base64,{img_base64}'\n",
    "\n",
    "# Get df metrics\n",
    "df_metrics = process_comments_and_get_metrics(df6)\n",
    "\n",
    "# Create Dash App\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "# Slider mark labels (hourly)\n",
    "marks = {\n",
    "    i: {'label': pd.to_datetime(i, unit='s').strftime('%H') + 'hr', 'style': {'transform': 'rotate(-90deg)', 'margin-left': '-10px'}}\n",
    "    for i in range(int(df1['Time'].min().timestamp()), int(df1['Time'].max().timestamp()) + 1, 3600)\n",
    "}\n",
    "\n",
    "\n",
    "# Layout App\n",
    "app.layout = html.Div(children=[\n",
    "    html.H1(\"Dashboard: Comment Analysis\"),\n",
    "\n",
    "    # First Graph: Pie chart\n",
    "    dcc.Graph(\n",
    "        id='sentiment-pie-chart',\n",
    "        figure=px.pie(\n",
    "            df_pie,\n",
    "            values='Count',\n",
    "            names='Sentiment Category',\n",
    "            title='Sentiment Category Distribution',\n",
    "            color_discrete_sequence=px.colors.sequential.Plasma,\n",
    "        ).update_layout(\n",
    "            xaxis=dict(title_text='Sentiment Category'),\n",
    "            yaxis=dict(title_text='Count'),\n",
    "        )\n",
    "    ),\n",
    "\n",
    "    # Second Graph: Histogram\n",
    "    dcc.Graph(\n",
    "        id='hourly-histogram',\n",
    "        figure=px.histogram(\n",
    "            df3,\n",
    "            x='Hour',\n",
    "            title='Distribution of Comments Over Hours',\n",
    "            color_discrete_sequence=['#7201a8']\n",
    "        ).update_layout(\n",
    "            xaxis_title='Hour',\n",
    "            yaxis_title='Comment Count'\n",
    "        )\n",
    "    ),\n",
    "\n",
    "    # Third Graph: Time Series Plot\n",
    "    html.Div([\n",
    "        html.H1(\"Comment Scores Over Time\"),\n",
    "\n",
    "        # Add sliders\n",
    "        dcc.RangeSlider(\n",
    "            id='time-slider',\n",
    "            marks=marks,\n",
    "            min=df1['Time'].min().timestamp(),\n",
    "            max=df1['Time'].max().timestamp(),\n",
    "            step=3600,  \n",
    "            value=[df1['Time'].min().timestamp(), df1['Time'].max().timestamp()]\n",
    "        ),\n",
    "\n",
    "        dcc.Graph(\n",
    "            id='line-chart',\n",
    "            config={'displayModeBar': False}  \n",
    "        )\n",
    "    ]),\n",
    "\n",
    "    # Fourth Graph: Comment Scores Bar Plot\n",
    "    html.Div([\n",
    "        html.H1(\"Comment Scores Bar Plot\"),\n",
    "\n",
    "        # Add dropdown with 4 features we want to display (ID, Score, Hour, Minute)\n",
    "        dcc.Dropdown(\n",
    "            id='x-axis-dropdown',\n",
    "            options=[\n",
    "                {'label': column, 'value': column}\n",
    "                for column in ['ID', 'Score', 'Hour', 'Minutes']  \n",
    "            ],\n",
    "            value='ID',  \n",
    "            style={'width': '50%'}\n",
    "        ),\n",
    "\n",
    "        dcc.Graph(\n",
    "            id='bar-chart',\n",
    "            config={'displayModeBar': False}  \n",
    "        )\n",
    "    ]),\n",
    "\n",
    "    # Fifth Element: Topic Word Cloud Generator\n",
    "    html.Div([\n",
    "        html.H1(\"Topic Word Cloud Generator\"),\n",
    "        dcc.Dropdown(\n",
    "            id='topic-dropdown',\n",
    "            options=[{'label': f'Topic {i}', 'value': i} for i in range(1, 11)],  \n",
    "            value=1,  \n",
    "            multi=False\n",
    "        ),\n",
    "        html.Div(id='wordcloud-container')\n",
    "    ]),\n",
    "    \n",
    "    # Sixth Element Word Frequency and Sentiment Analysis\n",
    "    html.Div([\n",
    "        html.H1(\"Word Sentiment Analysis - Sentiment and Frequency\"),\n",
    "\n",
    "        # Plotly Graph \n",
    "        dcc.Graph(\n",
    "            id='scatter-plot',\n",
    "            figure=px.scatter(\n",
    "                df_metrics,\n",
    "                x='Frequency',\n",
    "                y='Sentiment',\n",
    "                text='Word',\n",
    "                title='Sentiment and Frequency Scatter Plot',\n",
    "                color='Frequency',  # Set color based on Frequency\n",
    "                color_continuous_scale='plasma',  # Set color scale to 'plasma'\n",
    "            ).update_traces(mode='markers', marker=dict(size=10))\n",
    "        )\n",
    "    ]),\n",
    "    \n",
    "    # Seventh Element: Heatmap\n",
    "    html.Div([\n",
    "        html.H1(\"Heatmap Graph\"),\n",
    "    \n",
    "        dcc.Graph(\n",
    "            id='heatmap-graph',\n",
    "            figure=px.imshow(\n",
    "                heatmap_matrix,\n",
    "                labels=dict(x=\"Hour\", y=\"Score\"),\n",
    "                x=list(range(max_columns)),\n",
    "                y=list(range(num_rows)),\n",
    "                color_continuous_scale='Plasma'\n",
    "            ).update_layout(\n",
    "                title=\"Average Score by Hour (4x6 Grid)\",\n",
    "                xaxis_title=\"Column\",\n",
    "                yaxis_title=\"Hour (Row)\",\n",
    "                coloraxis_colorbar=dict(yanchor=\"middle\", y=0.5, x=-0.15),\n",
    "            )\n",
    "        )\n",
    "    ]),\n",
    "])\n",
    "\n",
    "\n",
    "# Define callback for Time Series Plot\n",
    "@app.callback(\n",
    "    Output('line-chart', 'figure'),\n",
    "    [Input('time-slider', 'value')]\n",
    ")\n",
    "def update_chart(selected_time_range):\n",
    "    start_time, end_time = selected_time_range\n",
    "    filtered_df = df1[(df1['Time'] >= pd.to_datetime(start_time, unit='s')) & (df1['Time'] <= pd.to_datetime(end_time, unit='s'))]\n",
    "\n",
    "    # Add color scale using 'Score'\n",
    "    fig = px.scatter(filtered_df, x='Time', y='Score', color='Score',title='Score Over Time (Zoomed In)', color_continuous_scale='plasma', opacity=0.6)\n",
    "                     \n",
    "    # Update color bar position to the right\n",
    "    fig.update_layout(coloraxis_colorbar=dict(yanchor=\"middle\", y=0.5, x=-0.25))\n",
    "\n",
    "    return fig\n",
    "\n",
    "# Define callback for Comment Scores Bar Plot\n",
    "@app.callback(\n",
    "    Output('bar-chart', 'figure'),\n",
    "    [Input('x-axis-dropdown', 'value')]\n",
    ")\n",
    "def update_bar_chart(selected_column):\n",
    "    # Create 'Score' bar chart\n",
    "    fig = px.bar(df2, x=selected_column, y='Score', title=f'Comment Scores - {selected_column}', color='Score',\n",
    "                 color_continuous_scale='Plasma')\n",
    "\n",
    "    fig.update_layout(coloraxis_colorbar=dict(yanchor=\"middle\", y=0.5, x=-0.25))\n",
    "\n",
    "    return fig\n",
    "\n",
    "# Define callback for Topic Word Cloud Generator\n",
    "@app.callback(\n",
    "    Output('wordcloud-container', 'children'),\n",
    "    [Input('topic-dropdown', 'value')]\n",
    ")\n",
    "def update_wordcloud(selected_topic):\n",
    "    wordcloud_img = generate_wordcloud(selected_topic)\n",
    "    if wordcloud_img:\n",
    "        return html.Img(src=wordcloud_img, style={'width': '80%', 'height': '80%'})\n",
    "    else:\n",
    "        return html.Div(\"No comments available for the selected topic.\")\n",
    "\n",
    "# Run app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True, port=8086)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2436ae08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
